# AWS DataSync Client Configuration Template
# This file will be customized during client setup
# Generated: [TIMESTAMP]
# Client: [CLIENT_NAME]

# ==============================================================================
# CLIENT INFORMATION
# ==============================================================================
export CLIENT_NAME="[CLIENT_NAME]"
export CLIENT_CONTACT="[CLIENT_CONTACT]"
export CLIENT_EMAIL="[CLIENT_EMAIL]"
export DEPLOYMENT_DATE="[DEPLOYMENT_DATE]"

# ==============================================================================
# AWS CONFIGURATION
# ==============================================================================
export AWS_PROFILE="[AWS_PROFILE]"
export AWS_REGION="[AWS_REGION]"
export AWS_ACCOUNT_ID="[AWS_ACCOUNT_ID]"

# ==============================================================================
# S3 CONFIGURATION
# ==============================================================================
export BUCKET_NAME="[BUCKET_NAME]"
export S3_BUCKET_ARN="arn:aws:s3:::[BUCKET_NAME]"
export S3_SUBDIRECTORY="[S3_SUBDIRECTORY]"
export S3_STORAGE_CLASS="INTELLIGENT_TIERING"

# S3 Transfer Configuration
# Maximum number of concurrent requests for S3 uploads
# AWS CLI default: 10
# Recommended values:
#   10  - Default, good balance for most use cases
#   15  - Better for many small files
#   20  - Maximum recommended (higher may cause throttling)
#   5   - Conservative, for limited bandwidth
export S3_MAX_CONCURRENT_REQUESTS="[S3_MAX_CONCURRENT_REQUESTS]"

# S3 Transfer Optimization Settings
# These settings control AWS CLI upload performance for large file datasets
# Adjust based on network bandwidth and file sizes
#
# Max concurrent S3 requests (AWS CLI default: 10)
# Recommended values:
#   10  - Default, good for <1 Gbps networks
#   20  - Recommended for 1-3 Gbps networks with large files
#   30  - Maximum for >3 Gbps networks (may cause throttling)
export AWS_CLI_S3_MAX_CONCURRENT_REQUESTS="[AWS_CLI_S3_MAX_CONCURRENT_REQUESTS]"

# Multipart upload threshold - files larger than this use multipart
# AWS CLI default: 8MB
# Recommended: 64MB for large file datasets (>100MB files)
export AWS_CLI_S3_MULTIPART_THRESHOLD="[AWS_CLI_S3_MULTIPART_THRESHOLD]"

# Multipart chunk size - size of each part in multipart uploads
# AWS CLI default: 8MB, max: 5GB
# Recommended: 64MB for 1-3 Gbps networks, 128MB for >3 Gbps
export AWS_CLI_S3_MULTIPART_CHUNKSIZE="[AWS_CLI_S3_MULTIPART_CHUNKSIZE]"

# Maximum bandwidth limit (optional throttling)
# Leave empty for unlimited, or set to limit (e.g., "500MB/s")
export AWS_CLI_S3_MAX_BANDWIDTH="[AWS_CLI_S3_MAX_BANDWIDTH]"

# ==============================================================================
# IAM CONFIGURATION
# ==============================================================================
export DATASYNC_ROLE_ARN="[DATASYNC_ROLE_ARN]"
export IAM_ROLE_NAME="[IAM_ROLE_NAME]"

# ==============================================================================
# CLOUDWATCH LOGGING
# ==============================================================================
export LOG_GROUP="[LOG_GROUP]"
export LOG_GROUP_ARN="[LOG_GROUP_ARN]"
export LOG_RETENTION_DAYS="[LOG_RETENTION_DAYS]"

# ==============================================================================
# PROJECT SETTINGS
# ==============================================================================
export PROJECT_TAG="[PROJECT_TAG]"
export ENVIRONMENT="[ENVIRONMENT]"

# ==============================================================================
# LOCAL DIRECTORIES
# ==============================================================================
export DATASYNC_HOME="[DATASYNC_HOME]"
export SOURCE_DIR="[SOURCE_DIR]"
export LOGS_DIR="[LOGS_DIR]"
export SCRIPTS_DIR="[SCRIPTS_DIR]"

# ==============================================================================
# CHECKSUM CONFIGURATION - AWS Additional Checksums Feature
# ==============================================================================
# Enable/disable checksum verification (true/false)
export ENABLE_CHECKSUM_VERIFICATION="true"

# AWS S3 Additional Checksums Algorithm (introduced Feb 2022, enhanced Dec 2024)
# Supported algorithms:
#   CRC64NVME - AWS default (Dec 2024), fastest for general use, 64-bit checksum
#   CRC32C    - Hardware accelerated (Intel SSE 4.2), ~3+ GB/s throughput
#   CRC32     - Standard CRC32, good performance
#   SHA256    - Cryptographic hash, slower (~240 MB/s) but required for compliance
#   SHA1      - Legacy cryptographic hash, not recommended
#   NONE      - Disable AWS checksums (legacy behavior, manual SHA256 only)
#
# Performance comparison for 100GB file:
#   CRC64NVME/CRC32C: ~30-60 seconds (hardware accelerated)
#   SHA256:           ~7+ minutes (CPU intensive)
#
# Recommendation: Use CRC64NVME for speed, SHA256 only for compliance requirements
export CHECKSUM_ALGORITHM="CRC64NVME"

# DEPRECATED: Legacy post-upload verification (downloads files to verify)
# AWS now verifies checksums automatically during upload using HTTP trailers
# For verification without downloads, the script uses 'aws s3api head-object'
# Setting this to 'true' is NOT RECOMMENDED - costly and slow
export VERIFY_AFTER_UPLOAD="false"

# ==============================================================================
# MONITORING CONFIGURATION
# ==============================================================================
# Hot folder check interval in seconds
export MONITOR_CHECK_INTERVAL="30"

# Email for alerts (if configured)
export ALERT_EMAIL="[ALERT_EMAIL]"

# SNS Topic ARN for alerts (will be populated if alerting is enabled)
export SNS_TOPIC_ARN="[SNS_TOPIC_ARN]"

# ==============================================================================
# DATASYNC AGENT CONFIGURATION (FOR FUTURE MIGRATION)
# ==============================================================================
# These will be populated when migrating to full DataSync agent
export AGENT_ARN=""
export SOURCE_LOCATION_ARN=""
export DEST_LOCATION_ARN=""
export TASK_ARN=""

# Migration status: "simulator" or "agent" or "parallel"
export DEPLOYMENT_MODE="simulator"

# ==============================================================================
# USAGE
# ==============================================================================
# This configuration is automatically sourced by scripts in the deployment.
# Scripts look for the config file relative to their location:
#   ../datasync-config.env (one level up from scripts/ directory)
#
# To manually load this configuration:
#   source /path/to/deployment/datasync-config.env
